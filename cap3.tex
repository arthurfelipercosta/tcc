\thispagestyle{myheadings}
\newpage

\chapter{Metodologia}

Este capítulo detalha a implementação técnica da solução desenvolvida, abordando a arquitetura e as tecnologias de seus três componentes principais: o backend de dados (api.py), a interface de consulta web e o assistente de comunicação via WhatsApp ({n8n\_bot.py}). Serão descritos os fluxos de trabalho que integram essas partes, demonstrando como os objetivos do projeto foram alcançados através do desenvolvimento prático.

\section{Etapas do Processo Metodológico}

O fluxo metodológico do projeto foi norteado pelas seguintes etapas principais:

\begin{enumerate}
    \item \textbf{Obtenção dos dados oficiais do PBEV:} Inicialmente, o arquivo em formato \textit{Portable Document Format} (PDF) contendo a base de veículos etiquetados foi baixado diretamente do portal oficial do INMETRO, responsável pelo PBEV \citep{INMETRO2024}.
    \item \textbf{Conversão de PDF para CSV:} Como o PDF não apresenta estrutura amigável para manipulação programática, procedeu-se com a conversão do arquivo para o formato \textit{Comma-Separated Values} (CSV) utilizando o serviço online Convertio \citep{CONVERTIO}, garantindo maior maleabilidade e compatibilidade com ferramentas de análise de dados.
    \item \textbf{Limpeza e preparação dos dados:} Os dados extraídos do PDF para CSV passaram por um processo de limpeza, padronização e eliminação de inconsistências, realizado no ambiente Jupyter Notebook (\textit{fix.ipynb}) com uso intensivo da biblioteca Pandas \citep{JUPYTER,PANDAS}. Posteriormente, foi gerado um segundo arquivo, \textit{dados\_corrigidos.csv}, para otimizar a unicidade dos dados, e desse arquivo, foi gerado um outro para poder apagar as linhas de dados duplicadas, \textit{dados\_corrigidos\_sem\_duplicatas.csv}.
    \item \textbf{Consumo, exposição e tratamento dos dados:} Com os arquivos finalizados, os dados foram consumidos pelas seguintes aplicações e componentes:
    \begin{itemize}
        \item \textit{api.py}: Servidor backend responsável por expor uma API RESTful que permite a consulta e filtragem dos dados corrigidos \citep{FLASK}.
        \item \textit{script.js}: Script do frontend que consome a API para alimentar a interface web, permitindo a seleção e comparação de veículos em tempo real.
         \item \textit{n8n\_bot.py}: componente de automação via WhatsApp, integrando N8N e Twilio para interação por mensagens e consulta automatizada \citep{N8N,TWILIO}.
    \end{itemize}
    \item \textbf{Tentativa de web scraping fracassada:} Antes da adoção da busca de preços na FIPE API \citep{FIPE}, realizou-se uma tentativa de coleta automatizada de uma média de preços via web scraping em grandes plataformas de anúncios de veículos (por exemplo, Webmotors) utilizando o script \textit{scrapping.js}. No entanto, devido a bloqueios de acesso e restrições impostas por essas plataformas, essa abordagem foi abandonada em favor dos dados vindos da API.
\end{enumerate}

\section{Tipo de Pesquisa e Ferramentas Utilizadas}
A pesquisa é classificada como aplicada, de natureza exploratória e descritiva, envolvendo o desenvolvimento de protótipo funcional. As principais ferramentas e tecnologias empregadas, todas referenciadas em detalhes na Bibliografia, incluem o ambiente Jupyter Notebook para manipulação e limpeza de dados \citep{JUPYTER}, as bibliotecas Pandas em Python para processamento dos arquivos CSV \citep{PANDAS,PYTHON} e o serviço do Convertio para a conversão de documentos \citep{CONVERTIO}. O desenvolvimento da solução envolveu o framework Flask para a exposição da API \citep{FLASK}, tecnologias como HTML, CSS e JavaScript para o desenvolvimento da interface web, as plataformas N8N e Twilio para a automação no WhatsApp \citep{N8N,TWILIO}. E as fontes de dados primárias dos arquivos oficiais do INMETRO/PBEV e da FIPE API \citep{INMETRO2024,FIPE}.

As subseções seguintes detalham cada etapa do processo, justificando as escolhas técnicas e metodológicas feitas.

\subsection{Obtenção dos Dados Oficiais do PBEV}
A fase inicial do projeto concentrou-se na aquisição de informações da base de dados veiculares que alimentaria o sistema. Optou-se pela utilização dos dados do PBEV, coordenado pelo INMETRO, devido à sua natureza oficial e confiabilidade das informações sobre eficiência energética e desempenho ambiental de boa parte da lista dos veículos rodando no país. O arquivo de dados é disponibilizado publicamente em formato \textit{Portable Document Format} (PDF) diretamente no portal do INMETRO \citep{INMETRO2024}. A escolha por uma fonte de dados governamental garantiu a precisão e a atualidade das informações, critérios fundamentais para a credibilidade do assistente veicular.

\subsection{Conversão de dados de PDF para CSV}
Considerando que o formato PDF, apesar de ideal para apresentação e preservação do layout, não é diretamente compatível com as necessidades de manipulação e análise de dados programática, a etapa seguinte consistiu na conversão dos arquivos baixados do PBEV para o formato \textit{Comma-Separated Values} (CSV). Para realizar essa transformação, foi empregado o serviço online gratuito \textbf{Convertio} \citep{CONVERTIO}. Esta ferramenta permitiu uma conversão do documento PDF em uma estrutura de texto em CSV, que é mais maleável e facilmente interpretável por linguagens de programação e bibliotecas de processamento de dados. A escolha do formato CSV foi estratégica, pois ele facilita o armazenamento e a transferência de dados entre diferentes softwares, sendo um padrão amplamente utilizado para conjuntos de dados e ideal para as próximas etapas de tratamento e consumo pela aplicação.

\subsection{Limpeza e Preparação dos Dados PBEV}
Com os dados obtidos no site do PBEV convertidos para CSV, a próxima etapa focou na limpeza e preparação desses dados para garantir a qualidade e consistência esperada das informações. Este processo foi conduzido em um ambiente \textit{Jupyter Notebook}, especificamente no arquivo '\textit{fix.ipynb}', que foi construído para permitir a execução interativa de código Python com a visualização imediata dos resultados de cada execução do código \citep{JUPYTER}. A biblioteca \textbf{Pandas} \citep{PANDAS} foi intensamente utilizada para:
\begin{itemize}
    \item Identificar e tratar valores ausentes ou inconsistentes.
    \item  Corrigir eventuais erros de digitação ou formatação gerados na hora da conversão.
    \item Padronizar os campos de texto e números.
\end{itemize}

Um script auxiliar intitulado de '\textit{fix\_encoding.py}' foi utilizado para resolver questões específicas de codificação de caracteres.
Ao final desta fase, foi gerado o arquivo '\textit{dados\_corrigidos.csv}', representando a primeira versão limpa e utilizável de dados, mas ainda após isso, uma etapa adicional foi realizada para remover as linhas que eram totalmente iguais, o que garante que não haja registros duplicados, otimizando o consumo pelas aplicações.

\subsection{Aquisição de Dados Complementares (Tabela FIPE)}
Diferentemente dos dados de especificações veiculares do PBEV, para a obtenção dos valores de mercado dos veículos, optou-se, inicialmente, pelo uso de web scrapping direto em páginas de sites confiáveis no mercado (ex: Webmotors), contudo, essa abordagem foi inviabilizada pela dificuldade em garantir a consistência e a disponibilidade contínua dos dados, a opção final utilizada no projeto foi a integração com a FIPE API \citep{FIPE}. Esta API pública oferece acesso direto e estruturado aos dados de marcas e valores da Tabela FIPE, que é o principal referencial de preços de automóveis no mercado brasileiro, conhecida por sua confiabilidade e constante atualização.

\subsection{Desenvolvimento do Backend (API Python)}
A API de backend do projeto foi implementada em Python, utilizando um framework web (Flask) para criar endpoints RESTful ('\textit{api,py}'). Essa API é a ponte entre a interface frontend (web e WhatsApp) e os dados veiculares processados. Suas responsabilidades incluem:

\begin{itemize}
    \item Receber e interpretar requisições HTTP (GET, POST) provenientes tanto da interface web quanto dos workflows do N8N \citep{PYTHON}.
    \item Acessar e manipular os dados veiculares (originários do PBEV e da FIPE API) já limpos e preparados em DataFrames Pandas.
    \item Aplicar lógicas de filtragem, busca e comparação de veículos com base nos parâmetros das requisições.
    \item Formatar e retornar as respostas aos clientes em formato JSON, garantindo uma comunicação eficiente e padronizada entre os componentes do sistema.
\end{itemize}

\subsection{Desenvolvimento do Frontend Web}
A interface web do projeto é composta pelos arquivos '\textit{index.html}' (estrutura), '\textit{styles.css}' (estilização) e '\textit{script.js}' (interatividade). Seu objetivo é proporcionar uma maneira visual e intuitiva para o usuário consultar e comparar dados de veículos. O '\textit{script.js}' atua como o motor dinâmico do frontend, implementando as seguintes funcionalidades:

\begin{itemize}
    \item Captura das entradas do usuário em formulários de busca e filtros.
    \item Envio de requisições assíncronas (via Fetch API) para os endpoints da API backend.
    \item Processamento das respostas em JSON recebidas do backend.
    \item Atualização dinâmica dos elementos da página `index.html` para exibir os resultados das consultas, como listas de veículos e tabelas comparativas detalhadas, sem a necessidade de recarregar a página.
\end{itemize}
É importante notar que esta interface web opera de forma autônoma em relação às integrações com N8N e Twilio, oferecendo um canal de acesso direto às informações veiculares.

\subsection{Automação e Comunicação via WhatsApp (N8N e Twilio)}
Para a funcionalidade de assistente conversacional via WhatsApp, o projeto integrou a plataforma de automação low-code \textbf{N8N} \citep{N8N} com o serviço de comunicação da \textbf{Twilio} \citep{TWILIO}, sendo orquestrado pelo script '\textit{n8n\_bot.py}'. O fluxo de interação ocorre da seguinte forma:

\begin{itemize}
    \item As mensagens são enviadas pelos usuários para o número de WhatsApp configurado na Twilio
    \item Essas mensagens são recebidas por um webhook no N8N.
    \item No N8N, workflows específicos são acionados para interpretar a intenção do usuário e orquestrar as ações subsequentes.
    \item Quando necessárias, requisições são feitas à API Python ('\textit{api.py}') para buscar, filtrar ou comparar dados veiculares conforme a solicitação do usuário.
    \item As informações retornadas pela API são processadas e formatadas dentro do N8N.
    \item A Twilio é utilizada para enviar de volta ao usuário as respostas que foram formatadas diretamente para o chat do usuário no WhatsApp, provendo uma experiência de atendimento automatizada e personalizada.
\end{itemize}
Esta arquitetura permite que o {n8n\_bot.py} atue como um intermediário eficiente, conectando os usuários do WhatsApp à base de dados veiculares de forma escalável e confiável.

\subsection{Tentativa e Abandono de Web Scrapping}
Em uma fase inicial do projeto, antes da consolidação das fontes de dados oficiais (FIPE API), explorou-se a possibilidade de coletar dados de veículos via web scrappin em grandes portais de classificados, como o Webmotors. Para isso, foi desenvolvido um script em JavaScript (scrapping.js) com o intuito de extrair informações de anúncios. No entanto, durante os testes, constatou-se que as plataformas de anúncios empregam mecanismos de proteção contra web scrapping, resultando em bloqueios frequentes de IPs e dificultando a extração consistente e confiável dos dados. Diante desses obstáculos técnicos e da necessidade de garantir a acurácia e atualização contínua das informações, a abordagem de web scrapping foi abandonada em favor da fonte de dados mais estável e programaticamente acessível (FIPE API).

\section{Considerações Finais da Metodologia}
A metodologia adotada para o desenvolvimento da solução, que inclui o assistente via WhatsApp ({n8n\_bot.py}) e suas interfaces web, priorizou a robustez, a confiabilidade das fontes de dados e a eficiência tecnológica. As etapas de aquisição, tratamento e exposição dos dados veiculares foram cuidadosamente planejadas para superar desafios técnicos e garantir a integridade das informações. A combinação de ferramentas de processamento de dados (Pandas, Jupyter), frameworks de desenvolvimento web (Flask, HTML/CSS/JS) e plataformas de automação e comunicação (N8N, Twilio) culminou em uma solução integrada. Esta solução não apenas valida a proposta de automação, mas também estabelece uma base sólida para futuras expansões e melhorias, oferecendo acesso eficiente a informações veiculares detalhadas tanto via interface web quanto por meio de um assistente conversacional no WhatsApp.